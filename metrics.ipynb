{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from src.dataset import Bigrammer\n",
    "from src.dataset_reader import sentence2words_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(102651, 64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrammer, w2v = torch.load(\"models/embedding.pth\")\n",
    "w2v.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_size = len(bigrammer.word2idx)\n",
    "m,_ = torch.max(torch.abs(w2v.weight), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64]) tensor([[-0.0785,  0.0371,  0.0719, -0.1542,  0.0559,  0.1083, -0.1175, -0.2281,\n",
      "         -0.1631,  0.0700,  0.0250, -0.0196,  0.1202,  0.1133, -0.0451,  0.2806,\n",
      "         -0.0919,  0.1375, -0.0587,  0.2352, -0.0828, -0.0337, -0.0672,  0.0778,\n",
      "         -0.0709, -0.0403,  0.0649,  0.0012, -0.1063, -0.0342, -0.1519,  0.1177,\n",
      "          0.2297,  0.0981,  0.1296, -0.1640,  0.0391, -0.0658, -0.1415, -0.0076,\n",
      "          0.0783,  0.0906,  0.1301,  0.1382, -0.2200, -0.0929,  0.0465, -0.0711,\n",
      "         -0.0004, -0.1556,  0.0417,  0.1611, -0.0250, -0.0372, -0.0395, -0.1294,\n",
      "          0.0758, -0.0476,  0.0395, -0.0509,  0.0225,  0.0681, -0.1601,  0.0360]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def get_norm_vec(word):\n",
    "    id_tensor = torch.LongTensor([bigrammer.word2idx[word]])\n",
    "    word_vec = w2v(id_tensor)\n",
    "    return word_vec / m\n",
    "\n",
    "word_vec = get_norm_vec(word)\n",
    "print(word_vec.shape ,word_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>word3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>capital-common-countries</td>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Baghdad</td>\n",
       "      <td>Iraq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>capital-common-countries</td>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capital-common-countries</td>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capital-common-countries</td>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>capital-common-countries</td>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Bern</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         type   word1   word2    word3       target\n",
       "idx                                                                \n",
       "0    capital-common-countries  Athens  Greece  Baghdad         Iraq\n",
       "1    capital-common-countries  Athens  Greece  Bangkok     Thailand\n",
       "2    capital-common-countries  Athens  Greece  Beijing        China\n",
       "3    capital-common-countries  Athens  Greece   Berlin      Germany\n",
       "4    capital-common-countries  Athens  Greece     Bern  Switzerland"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_csv(\"data/google-analogies.csv\", index_col=0)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19544, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = test_set.columns\n",
    "vals = test_set.values\n",
    "vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cases: 16600 present / 2944 not present\n"
     ]
    }
   ],
   "source": [
    "pr, not_pr = 0, 0\n",
    "clean_set = defaultdict(list)\n",
    "for val in vals:\n",
    "    cat, words = val[0], val[1:]\n",
    "    words = [w.lower() for w in words]\n",
    "    # check if all are present\n",
    "    if all([w in bigrammer.word2idx for w in words]):\n",
    "        pr += 1\n",
    "        clean_set[cat].append(words)\n",
    "    else:\n",
    "        not_pr += 1\n",
    "\n",
    "print(\"Test cases: {} present / {} not present\".format(pr, not_pr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3CosAdd by categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8944)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cos(a,b):\n",
    "    a = a.flatten()\n",
    "    b = b.flatten()\n",
    "    return a @ b / (a.norm() * b.norm())\n",
    "\n",
    "\n",
    "a = torch.tensor([1.0, 0.0]).view(1,2).float()\n",
    "b = torch.tensor([1.0, 0.5]).view(1,2).float()\n",
    "\n",
    "cos(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = {} # category -> list of cosine dists\n",
    "for cat, samples in clean_set.items():\n",
    "    distances[cat] = []\n",
    "    for case in samples:\n",
    "        # 1. get all 4 vectors:\n",
    "        vecs = [get_norm_vec(w) for w in case]\n",
    "        # 2. calculate distance to target (case[3])\n",
    "        target = vecs[3]\n",
    "        destination = vecs[2] + (vecs[1] - vecs[0])\n",
    "        distances[cat].append(abs(cos(target, destination).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capital-common-countries\n",
      "\t max:\t0.737\n",
      "\t mean:\t0.363\n",
      "\t std:\t0.172\n",
      "capital-world\n",
      "\t max:\t0.737\n",
      "\t mean:\t0.222\n",
      "\t std:\t0.138\n",
      "currency\n",
      "\t max:\t0.462\n",
      "\t mean:\t0.119\n",
      "\t std:\t0.093\n",
      "city-in-state\n",
      "\t max:\t0.756\n",
      "\t mean:\t0.332\n",
      "\t std:\t0.144\n",
      "family\n",
      "\t max:\t0.927\n",
      "\t mean:\t0.409\n",
      "\t std:\t0.221\n",
      "gram1-adjective-to-adverb\n",
      "\t max:\t0.689\n",
      "\t mean:\t0.266\n",
      "\t std:\t0.174\n",
      "gram2-opposite\n",
      "\t max:\t0.602\n",
      "\t mean:\t0.178\n",
      "\t std:\t0.121\n",
      "gram3-comparative\n",
      "\t max:\t0.792\n",
      "\t mean:\t0.349\n",
      "\t std:\t0.191\n",
      "gram4-superlative\n",
      "\t max:\t0.755\n",
      "\t mean:\t0.259\n",
      "\t std:\t0.181\n",
      "gram5-present-participle\n",
      "\t max:\t0.780\n",
      "\t mean:\t0.322\n",
      "\t std:\t0.172\n",
      "gram6-nationality-adjective\n",
      "\t max:\t0.761\n",
      "\t mean:\t0.345\n",
      "\t std:\t0.190\n",
      "gram7-past-tense\n",
      "\t max:\t0.771\n",
      "\t mean:\t0.346\n",
      "\t std:\t0.185\n",
      "gram8-plural\n",
      "\t max:\t0.803\n",
      "\t mean:\t0.294\n",
      "\t std:\t0.183\n",
      "gram9-plural-verbs\n",
      "\t max:\t0.752\n",
      "\t mean:\t0.301\n",
      "\t std:\t0.179\n"
     ]
    }
   ],
   "source": [
    "all_dists = []\n",
    "cats_mean_dists = []\n",
    "def print_stat(metrics):\n",
    "    print(\"\\t max:\\t{:.3f}\".format(metrics[0]))\n",
    "    print(\"\\t mean:\\t{:.3f}\".format(metrics[1]))\n",
    "    print(\"\\t std:\\t{:.3f}\".format(metrics[2]))\n",
    "    \n",
    "for cat, cs in distances.items():\n",
    "    print(cat)\n",
    "    metrics = (np.max(cs), np.mean(cs), np.std(cs))\n",
    "    print_stat(metrics)\n",
    "    all_dists += cs\n",
    "    cats_mean_dists.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics between categories:\n",
      "\t max:\t0.737\n",
      "\t mean:\t0.293\n",
      "\t std:\t0.167\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean metrics between categories:\")\n",
    "metrics = np.array(cats_mean_dists).mean(axis=0)\n",
    "print_stat(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For all test set:\n",
      "\t max:\t0.927\n",
      "\t mean:\t0.296\n",
      "\t std:\t0.179\n"
     ]
    }
   ],
   "source": [
    "print(\"For all test set:\")\n",
    "cs = all_dists\n",
    "print_stat((np.max(cs), np.mean(cs), np.std(cs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
